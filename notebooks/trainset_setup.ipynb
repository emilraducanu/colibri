{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Text Cleaning**\\\n",
    "Remove any unnecessary characters, such as special characters, punctuation, or HTML tags.\n",
    "Convert the text to lowercase to achieve case-insensitive matching.\n",
    "Remove any extra whitespace or leading/trailing spaces.\n",
    "2. **Tokenization**\\\n",
    "Split the text into individual words or tokens, as it helps the model understand the semantic meaning of each word.\n",
    "3. **Stopword Removal**\\\n",
    "Remove common words, known as stopwords (e.g., \"the,\" \"is,\" \"and\"), which may not contribute much to the classification task.\n",
    "You can use pre-defined stopword lists from libraries like NLTK or spaCy or create a custom list based on your specific domain.\n",
    "4. **Lemmatization or Stemming**\\\n",
    "Reduce words to their base or root form to normalize the text and reduce vocabulary size.\n",
    "Lemmatization aims to convert words to their base form (lemma) using linguistic rules.\n",
    "Stemming reduces words to their root form using simple heuristic algorithms.\n",
    "5. **Handling Abbreviations and Acronyms**\\\n",
    "Decide whether to expand or keep abbreviations and acronyms as they are, based on their relevance to the classification task.\n",
    "6. **Handling Numeric Data**\\\n",
    "Decide whether to replace numbers with a generic token or keep them as-is based on their importance in the text.\n",
    "7. **Handling Rare Words or Outliers**\\\n",
    "Remove extremely rare words that occur infrequently, as they may not contribute significantly to the classification task.\n",
    "Similarly, remove any outliers or unusual words that may not be relevant to the task.\n",
    "8. **Vectorization**\\\n",
    "Convert the pre-processed text data into numerical representations that machine learning models can understand.\n",
    "Techniques such as TF-IDF (Term Frequency-Inverse Document Frequency) or word embeddings like Word2Vec or GloVe can be employed for vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/er/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/er/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/er/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw database contains 1007 entries (217 included MA and 790 excluded MA), stored into 'raw_data' variable.\n"
     ]
    }
   ],
   "source": [
    "# ------- LOADING DATA INTO A DATAFRAME -------\n",
    "\n",
    "\n",
    "# Loading database created by D. Beillouin et al.\n",
    "xlsx_file = pd.ExcelFile(\n",
    "    \"/home/er/Documents/Cirad/SOCSciCompiler/data/trainset/trainset.xlsx\"\n",
    ")\n",
    "\n",
    "# Adding label \"excluded\" or \"included\" for each MA\n",
    "df_incl = xlsx_file.parse(\"retained_meta-analyses\")\n",
    "df_excl = xlsx_file.parse(\"non_retained_meta-analyses\")\n",
    "df_incl[\"Screening\"] = \"included\"\n",
    "df_excl[\"Screening\"] = \"excluded\"\n",
    "\n",
    "# Keeping only useful attributes\n",
    "attributes_to_keep_incl = [\n",
    "    \"Screening\",\n",
    "    \"link\",\n",
    "    \"Article Title\",\n",
    "    \"Abstract\",\n",
    "    \"Keywords\",\n",
    "]\n",
    "attributes_to_keep_excl = [\n",
    "    \"Screening\",\n",
    "    \"lien pour accès\",\n",
    "    \"title\",\n",
    "    \"Abstract\",\n",
    "    \"Keywords\",\n",
    "]\n",
    "df_incl = df_incl[attributes_to_keep_incl]\n",
    "df_excl = df_excl[attributes_to_keep_excl]\n",
    "\n",
    "# Standardising columns names\n",
    "new_column_names_incl = {\"Article Title\": \"Title\", \"link\": \"DOI\"}\n",
    "new_column_names_excl = {\"title\": \"Title\", \"lien pour accès\": \"DOI\"}\n",
    "df_incl = df_incl.rename(columns=new_column_names_incl)\n",
    "df_excl = df_excl.rename(columns=new_column_names_excl)\n",
    "\n",
    "# Merging exluded and included MA into single dataframe\n",
    "raw_data = pd.concat([df_incl, df_excl], ignore_index=True)\n",
    "raw_data = raw_data.fillna(\"\")\n",
    "\n",
    "size_1 = len(df_incl)\n",
    "size_2 = len(df_excl)\n",
    "size_3 = size_1 + size_2\n",
    "print(\n",
    "    f\"Raw database contains {size_3} entries ({size_1} included MA and {size_2} excluded MA), stored into 'raw_data' variable.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 rows removed because of empty DOIs. Cannot check the uniqueness.\n",
      "0 rows removed because of empty titles. Cannot be processed by the ML model.\n",
      "54 rows removed because of empty abstracts. Cannot be processed by the ML model.\n",
      "8 DOI duplicates and title duplicates removed.\n",
      "Cleaned database contains 794 entries (212 included MA and 582 excluded MA), stored into 'train_set' variable.\n"
     ]
    }
   ],
   "source": [
    "# ------- CLEANING -------\n",
    "\n",
    "\n",
    "# Function to get DOIs from URLs\n",
    "def extract_doi(url):\n",
    "    if str(url).startswith(\"https://doi.org/\"):\n",
    "        return str(url)[len(\"https://doi.org/\") :]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extracting DOIs from URLs\n",
    "raw_data[\"DOI\"] = raw_data[\"DOI\"].apply(extract_doi)\n",
    "\n",
    "# Removing empty DOIs rows\n",
    "raw_data = raw_data.dropna(subset=[\"DOI\"])\n",
    "size_4 = len(raw_data)\n",
    "size_5 = size_3 - size_4\n",
    "print(f\"{size_5} rows removed because of empty DOIs. Cannot check the uniqueness.\")\n",
    "\n",
    "# Removing empty titles rows\n",
    "raw_data[\"Title\"] = raw_data[\"Title\"].replace(\"\", np.nan)\n",
    "raw_data = raw_data.dropna(subset=[\"Title\"])\n",
    "size_6 = len(raw_data)\n",
    "size_7 = size_4 - size_6\n",
    "print(\n",
    "    f\"{size_7} rows removed because of empty titles. Cannot be processed by the ML model.\"\n",
    ")\n",
    "\n",
    "# Removing empty abstracts rows\n",
    "raw_data[\"Abstract\"] = raw_data[\"Abstract\"].replace(\"\", np.nan)\n",
    "raw_data = raw_data.dropna(subset=[\"Abstract\"])\n",
    "size_8 = len(raw_data)\n",
    "size_9 = size_6 - size_8\n",
    "print(\n",
    "    f\"{size_9} rows removed because of empty abstracts. Cannot be processed by the ML model.\"\n",
    ")\n",
    "\n",
    "# Removing DOIs duplicates and titles duplicates\n",
    "raw_data = raw_data.drop_duplicates(subset=[\"DOI\"], keep=\"first\")\n",
    "raw_data = raw_data.drop_duplicates(subset=\"Title\", keep=\"first\")\n",
    "size_10 = len(raw_data)\n",
    "size_11 = size_8 - size_10\n",
    "print(f\"{size_11} DOI duplicates and title duplicates removed.\")\n",
    "\n",
    "# Droping column 'DOI' now we have unique values. No needed for the ML model\n",
    "train_set = raw_data.drop(columns=[\"DOI\"])\n",
    "\n",
    "size_12 = train_set[\"Screening\"].value_counts()\n",
    "size_incl = size_12.loc[\"included\"]\n",
    "size_excl = size_12.loc[\"excluded\"]\n",
    "print(\n",
    "    f\"Cleaned database contains {size_10} entries ({size_incl} included MA and {size_excl} excluded MA), stored into 'train_set' variable.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set stored into 'train_set' variable and ready to be used.\n",
      "Summary with the 20 first lines:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screening</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>included</td>\n",
       "      <td>[global, pattern, dynamic, soil, carbon, nitro...</td>\n",
       "      <td>[afforestation, proposed, effective, method, c...</td>\n",
       "      <td>[afforestation, carbonnitrogen, interaction, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>included</td>\n",
       "      <td>[effect, different, fertilization, mode, soil,...</td>\n",
       "      <td>[evidence, shown, fertilizer, application, cou...</td>\n",
       "      <td>[paddy, field, fertilization, soil, organic, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[efficacy, tilmanocept, sentinel, lymph, mode,...</td>\n",
       "      <td>[sentinel, lymph, node, sln, mapping, common, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>included</td>\n",
       "      <td>[experimental, observational, study, find, con...</td>\n",
       "      <td>[manipulative, experiment, observation, along,...</td>\n",
       "      <td>[agriculturemethods, carbonanalysis, climate, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[atmospheric, co2, soil, extracellular, enzyme...</td>\n",
       "      <td>[rising, atmospheric, co2, concentration, alte...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>included</td>\n",
       "      <td>[effect, straw, retention, crop, yield, soil, ...</td>\n",
       "      <td>[crop, straw, retention, field, csrf, technolo...</td>\n",
       "      <td>[metaanalysizs, straw, retention, crop, yield,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[costeffectiveness, analysis, bezlotoxumab, ad...</td>\n",
       "      <td>[introductionclostridium, difficile, infection...</td>\n",
       "      <td>[bezlotoxumab, clostridium, difficile, infecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[review, allometric, equation, major, land, co...</td>\n",
       "      <td>[review, biomass, study, conducted, 11, southe...</td>\n",
       "      <td>[allometry, wood, density, carbon, land, cover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>included</td>\n",
       "      <td>[grazing, improves, c, n, cycling, northern, g...</td>\n",
       "      <td>[grazing, potentially, alters, grassland, ecos...</td>\n",
       "      <td>[agriculture, animal, carbon, cycle, conservat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>included</td>\n",
       "      <td>[enhanced, top, soil, carbon, stock, organic, ...</td>\n",
       "      <td>[suggested, conversion, organic, farming, cont...</td>\n",
       "      <td>[climate, change, soil, quality, agricultural,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[stimulation, n2o, emission, manure, applicati...</td>\n",
       "      <td>[animal, manure, application, organic, fertili...</td>\n",
       "      <td>[animal, manure, emission, factor, greenhouse,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>included</td>\n",
       "      <td>[response, ecosystem, carbon, cycle, experimen...</td>\n",
       "      <td>[global, warming, potentially, alters, terrest...</td>\n",
       "      <td>[cclimate, feedback, c, efflux, c, influx, c, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[ecosystem, service, biologically, diversified...</td>\n",
       "      <td>[hypothesize, biological, diversification, acr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>included</td>\n",
       "      <td>[organic, amendment, increase, crop, yield, im...</td>\n",
       "      <td>[although, numerous, study, suggest, organic, ...</td>\n",
       "      <td>[organic, amendment, crop, yield, soil, extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[soil, microbial, response, forest, floor, lit...</td>\n",
       "      <td>[change, litterfall, dynamic, soil, property, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[review, mechanical, effect, plant, root, conc...</td>\n",
       "      <td>[living, plant, root, modify, mechanical, hydr...</td>\n",
       "      <td>[concentrated, flow, erosion, soil, detachment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>included</td>\n",
       "      <td>[denitrification, upland, china, magnitude, in...</td>\n",
       "      <td>[better, understanding, influencing, factor, a...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[precareer, perception, gendered, work, perfor...</td>\n",
       "      <td>[according, united, state, census, bureau, wom...</td>\n",
       "      <td>[referent, gendered, work, performance, equity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[antiepileptic, drug, increase, risk, infectio...</td>\n",
       "      <td>[aim, experimental, study, show, antiepileptic...</td>\n",
       "      <td>[adverse, effect, antiepileptic, drug, infecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>excluded</td>\n",
       "      <td>[response, soil, carbon, nitrogen, 15year, exp...</td>\n",
       "      <td>[although, qinghaitibetan, plateau, qtp, exper...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Screening                                              Title  \\\n",
       "0   included  [global, pattern, dynamic, soil, carbon, nitro...   \n",
       "1   included  [effect, different, fertilization, mode, soil,...   \n",
       "2   excluded  [efficacy, tilmanocept, sentinel, lymph, mode,...   \n",
       "3   included  [experimental, observational, study, find, con...   \n",
       "4   excluded  [atmospheric, co2, soil, extracellular, enzyme...   \n",
       "5   included  [effect, straw, retention, crop, yield, soil, ...   \n",
       "6   excluded  [costeffectiveness, analysis, bezlotoxumab, ad...   \n",
       "7   excluded  [review, allometric, equation, major, land, co...   \n",
       "8   included  [grazing, improves, c, n, cycling, northern, g...   \n",
       "9   included  [enhanced, top, soil, carbon, stock, organic, ...   \n",
       "10  excluded  [stimulation, n2o, emission, manure, applicati...   \n",
       "11  included  [response, ecosystem, carbon, cycle, experimen...   \n",
       "12  excluded  [ecosystem, service, biologically, diversified...   \n",
       "13  included  [organic, amendment, increase, crop, yield, im...   \n",
       "14  excluded  [soil, microbial, response, forest, floor, lit...   \n",
       "15  excluded  [review, mechanical, effect, plant, root, conc...   \n",
       "16  included  [denitrification, upland, china, magnitude, in...   \n",
       "17  excluded  [precareer, perception, gendered, work, perfor...   \n",
       "18  excluded  [antiepileptic, drug, increase, risk, infectio...   \n",
       "19  excluded  [response, soil, carbon, nitrogen, 15year, exp...   \n",
       "\n",
       "                                             Abstract  \\\n",
       "0   [afforestation, proposed, effective, method, c...   \n",
       "1   [evidence, shown, fertilizer, application, cou...   \n",
       "2   [sentinel, lymph, node, sln, mapping, common, ...   \n",
       "3   [manipulative, experiment, observation, along,...   \n",
       "4   [rising, atmospheric, co2, concentration, alte...   \n",
       "5   [crop, straw, retention, field, csrf, technolo...   \n",
       "6   [introductionclostridium, difficile, infection...   \n",
       "7   [review, biomass, study, conducted, 11, southe...   \n",
       "8   [grazing, potentially, alters, grassland, ecos...   \n",
       "9   [suggested, conversion, organic, farming, cont...   \n",
       "10  [animal, manure, application, organic, fertili...   \n",
       "11  [global, warming, potentially, alters, terrest...   \n",
       "12  [hypothesize, biological, diversification, acr...   \n",
       "13  [although, numerous, study, suggest, organic, ...   \n",
       "14  [change, litterfall, dynamic, soil, property, ...   \n",
       "15  [living, plant, root, modify, mechanical, hydr...   \n",
       "16  [better, understanding, influencing, factor, a...   \n",
       "17  [according, united, state, census, bureau, wom...   \n",
       "18  [aim, experimental, study, show, antiepileptic...   \n",
       "19  [although, qinghaitibetan, plateau, qtp, exper...   \n",
       "\n",
       "                                             Keywords  \n",
       "0   [afforestation, carbonnitrogen, interaction, d...  \n",
       "1   [paddy, field, fertilization, soil, organic, c...  \n",
       "2                                                  []  \n",
       "3   [agriculturemethods, carbonanalysis, climate, ...  \n",
       "4                                                  []  \n",
       "5   [metaanalysizs, straw, retention, crop, yield,...  \n",
       "6   [bezlotoxumab, clostridium, difficile, infecti...  \n",
       "7   [allometry, wood, density, carbon, land, cover...  \n",
       "8   [agriculture, animal, carbon, cycle, conservat...  \n",
       "9   [climate, change, soil, quality, agricultural,...  \n",
       "10  [animal, manure, emission, factor, greenhouse,...  \n",
       "11  [cclimate, feedback, c, efflux, c, influx, c, ...  \n",
       "12                                                 []  \n",
       "13  [organic, amendment, crop, yield, soil, extrac...  \n",
       "14                                                 []  \n",
       "15  [concentrated, flow, erosion, soil, detachment...  \n",
       "16                                                 []  \n",
       "17    [referent, gendered, work, performance, equity]  \n",
       "18  [adverse, effect, antiepileptic, drug, infecti...  \n",
       "19                                                 []  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------- PRE-PROCESSING -------\n",
    "\n",
    "\n",
    "# PRE-PROCESSING TITLES\n",
    "\n",
    "\n",
    "# Function to pre-process values of columns Title, Abstract and Keywords\n",
    "def preprocessor(column: str):\n",
    "    token_col = []\n",
    "    for val in train_set[column]:\n",
    "        val = re.sub(r\"[^\\w\\s]\", \"\", val)  # Remove special characters/punctuation\n",
    "        val = val.lower()  # Convert to lowercase\n",
    "        val = val.strip()  # Remove leading/trailing spaces\n",
    "        tokens = nltk.word_tokenize(val)  # Tokenization\n",
    "        filtered_tokens = [\n",
    "            token for token in tokens if token not in stopwords\n",
    "        ]  # Stopword Removal\n",
    "        lemmas = [\n",
    "            lemmatizer.lemmatize(token) for token in filtered_tokens\n",
    "        ]  # Lemmatization\n",
    "        token_col.append(lemmas)\n",
    "    train_set[column] = token_col\n",
    "\n",
    "\n",
    "# Applying 'preprocessor()' to each column\n",
    "preprocessor('Title')\n",
    "preprocessor('Abstract')\n",
    "preprocessor('Keywords')\n",
    "\n",
    "# Shuffling and re-indexing\n",
    "train_set = train_set.sample(frac=1)\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "\n",
    "print(\"Training set stored into 'train_set' variable and ready to be used.\")\n",
    "print(\"Summary with the 20 first lines:\")\n",
    "train_set.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # Assuming your DataFrame is called 'df' and it contains the columns 'Title', 'Abstract', 'Keywords'\n",
    "\n",
    "# # Step 7: Handling Rare Words or Outliers\n",
    "# # Remove extremely rare words or outliers using a threshold\n",
    "# threshold = 0.01  # Adjust the threshold as per your requirement\n",
    "# df[\"Title\"] = df[\"Title\"].apply(\n",
    "#     lambda x: \" \".join(\n",
    "#         [\n",
    "#             word\n",
    "#             for word in x.split()\n",
    "#             if df[\"Title\"].str.count(word).sum() / len(df) > threshold\n",
    "#         ]\n",
    "#     )\n",
    "# )\n",
    "# df[\"Abstract\"] = df[\"Abstract\"].apply(\n",
    "#     lambda x: \" \".join(\n",
    "#         [\n",
    "#             word\n",
    "#             for word in x.split()\n",
    "#             if df[\"Abstract\"].str.count(word).sum() / len(df) > threshold\n",
    "#         ]\n",
    "#     )\n",
    "# )\n",
    "# df[\"Keywords\"] = df[\"Keywords\"].apply(\n",
    "#     lambda x: \" \".join(\n",
    "#         [\n",
    "#             word\n",
    "#             for word in x.split()\n",
    "#             if df[\"Keywords\"].str.count(word).sum() / len(df) > threshold\n",
    "#         ]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Step 8: Vectorization\n",
    "# # Perform TF-IDF vectorization on 'Title', 'Abstract', and 'Keywords'\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# title_vectorized = vectorizer.fit_transform(df[\"Title\"])\n",
    "# abstract_vectorized = vectorizer.fit_transform(df[\"Abstract\"])\n",
    "# keywords_vectorized = vectorizer.fit_transform(df[\"Keywords\"])\n",
    "\n",
    "# # Convert the vectorized data into DataFrames\n",
    "# title_vectorized_df = pd.DataFrame(\n",
    "#     title_vectorized.toarray(), columns=vectorizer.get_feature_names()\n",
    "# )\n",
    "# abstract_vectorized_df = pd.DataFrame(\n",
    "#     abstract_vectorized.toarray(), columns=vectorizer.get_feature_names()\n",
    "# )\n",
    "# keywords_vectorized_df = pd.DataFrame(\n",
    "#     keywords_vectorized.toarray(), columns=vectorizer.get_feature_names()\n",
    "# )\n",
    "\n",
    "# # Concatenate the vectorized DataFrames with the original DataFrame\n",
    "# df = pd.concat(\n",
    "#     [df, title_vectorized_df, abstract_vectorized_df, keywords_vectorized_df], axis=1\n",
    "# )\n",
    "\n",
    "# # Display the updated DataFrame\n",
    "# print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
