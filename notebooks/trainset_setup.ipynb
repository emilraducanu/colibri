{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning\n",
    "    Remove any unnecessary characters, such as special characters, punctuation, or HTML tags.\n",
    "    Convert the text to lowercase to achieve case-insensitive matching.\n",
    "    Remove any extra whitespace or leading/trailing spaces.\n",
    "\n",
    "### Tokenization\n",
    "    Split the text into individual words or tokens, as it helps the model understand the semantic meaning of each word.\n",
    "\n",
    "### Stopword Removal\n",
    "    Remove common words, known as stopwords (e.g., \"the,\" \"is,\" \"and\"), which may not contribute much to the classification task.\n",
    "    You can use pre-defined stopword lists from libraries like NLTK or spaCy or create a custom list based on your specific domain.\n",
    "\n",
    "### Lemmatization or Stemming\n",
    "    Reduce words to their base or root form to normalize the text and reduce vocabulary size.\n",
    "    Lemmatization aims to convert words to their base form (lemma) using linguistic rules.\n",
    "    Stemming reduces words to their root form using simple heuristic algorithms.\n",
    "\n",
    "### Handling Abbreviations and Acronyms\n",
    "    Decide whether to expand or keep abbreviations and acronyms as they are, based on their relevance to the classification task.\n",
    "\n",
    "### Handling Numeric Data\n",
    "    Decide whether to replace numbers with a generic token or keep them as-is based on their importance in the text.\n",
    "\n",
    "### Handling Rare Words or Outliers\n",
    "    Remove extremely rare words that occur infrequently, as they may not contribute significantly to the classification task.\n",
    "    Similarly, remove any outliers or unusual words that may not be relevant to the task.\n",
    "\n",
    "### Vectorization\n",
    "    Convert the pre-processed text data into numerical representations that machine learning models can understand.\n",
    "    Techniques such as TF-IDF (Term Frequency-Inverse Document Frequency) or word embeddings like Word2Vec or GloVe can be employed for vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/er/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/er/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/er/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw database contains 1007 entries (217 included MA and 790 excluded MA)\n",
      "Raw database stored into 'raw_data' variable\n",
      "'raw_data' information\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1007 entries, 0 to 1006\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Screening  1007 non-null   object\n",
      " 1   DOI        1007 non-null   object\n",
      " 2   Title      1007 non-null   object\n",
      " 3   Abstract   1007 non-null   object\n",
      " 4   Keywords   1007 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 39.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screening</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1111/gcbb.12234</td>\n",
       "      <td>Emission of CO2 from biochar-amended soils and...</td>\n",
       "      <td>Soil amendment with pyrogenic organic matter (...</td>\n",
       "      <td>additive effects; carbon sequestration; decomp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1890/10-0660.1</td>\n",
       "      <td>Fire effects on temperate forest soil C and N ...</td>\n",
       "      <td>Temperate forest soils store globally signific...</td>\n",
       "      <td>carbon sinks; fire; forest management; meta-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1016/j.still.2020.104575</td>\n",
       "      <td>A calculator to quantify cover crop effects on...</td>\n",
       "      <td>Many producers use cover crops as a means to i...</td>\n",
       "      <td>Conservation agriculture; Soil quality; Meta-A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1016/j.dib.2020.105376</td>\n",
       "      <td>Quantifying cover crop effects on soil health ...</td>\n",
       "      <td>The dataset presented here supports the resear...</td>\n",
       "      <td>Soil health\\nSoil quality\\nCover crop\\nConserv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1016/j.foreco.2019.117808</td>\n",
       "      <td>Impacts of the Three-North shelter forest prog...</td>\n",
       "      <td>Vegetation restoration in arid and semi-arid a...</td>\n",
       "      <td>Three-North Shelter Forest; Soil organic carbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1088/1748-9326/aaeb5f</td>\n",
       "      <td>Revisiting IPCC Tier 1 coefficients for soil o...</td>\n",
       "      <td>Agroforestry systems comprise trees and crops,...</td>\n",
       "      <td>carbon sequestration; emission factor; climate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1111/sum.12546</td>\n",
       "      <td>Biochar effects on crop yields with and withou...</td>\n",
       "      <td>The added value of biochar when applied along ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1016/j.agee.2016.04.011</td>\n",
       "      <td>Carbon sequestration and net emissions of CH4 ...</td>\n",
       "      <td>While there have been many valuable individual...</td>\n",
       "      <td>Agroforestry\\nCarbon sequestration\\nSoil\\nBiom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1007/s10457-017-0147-9</td>\n",
       "      <td>Soil carbon sequestration in agroforestry syst...</td>\n",
       "      <td>Agroforestry systems may play an important rol...</td>\n",
       "      <td>Agroforestry; Carbon sequestration; Soil organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>included</td>\n",
       "      <td>https://doi.org/10.1016/j.foreco.2018.07.029</td>\n",
       "      <td>The effects of forest restoration on ecosystem...</td>\n",
       "      <td>Ecological restoration has become an overarchi...</td>\n",
       "      <td>Pacific Northwest; Ecosystem services; Silvicu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Screening                                           DOI  \\\n",
       "0  included            https://doi.org/10.1111/gcbb.12234   \n",
       "1  included             https://doi.org/10.1890/10-0660.1   \n",
       "2  included   https://doi.org/10.1016/j.still.2020.104575   \n",
       "3  included     https://doi.org/10.1016/j.dib.2020.105376   \n",
       "4  included  https://doi.org/10.1016/j.foreco.2019.117808   \n",
       "5  included      https://doi.org/10.1088/1748-9326/aaeb5f   \n",
       "6  included             https://doi.org/10.1111/sum.12546   \n",
       "7  included    https://doi.org/10.1016/j.agee.2016.04.011   \n",
       "8  included     https://doi.org/10.1007/s10457-017-0147-9   \n",
       "9  included  https://doi.org/10.1016/j.foreco.2018.07.029   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Emission of CO2 from biochar-amended soils and...   \n",
       "1  Fire effects on temperate forest soil C and N ...   \n",
       "2  A calculator to quantify cover crop effects on...   \n",
       "3  Quantifying cover crop effects on soil health ...   \n",
       "4  Impacts of the Three-North shelter forest prog...   \n",
       "5  Revisiting IPCC Tier 1 coefficients for soil o...   \n",
       "6  Biochar effects on crop yields with and withou...   \n",
       "7  Carbon sequestration and net emissions of CH4 ...   \n",
       "8  Soil carbon sequestration in agroforestry syst...   \n",
       "9  The effects of forest restoration on ecosystem...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Soil amendment with pyrogenic organic matter (...   \n",
       "1  Temperate forest soils store globally signific...   \n",
       "2  Many producers use cover crops as a means to i...   \n",
       "3  The dataset presented here supports the resear...   \n",
       "4  Vegetation restoration in arid and semi-arid a...   \n",
       "5  Agroforestry systems comprise trees and crops,...   \n",
       "6  The added value of biochar when applied along ...   \n",
       "7  While there have been many valuable individual...   \n",
       "8  Agroforestry systems may play an important rol...   \n",
       "9  Ecological restoration has become an overarchi...   \n",
       "\n",
       "                                            Keywords  \n",
       "0  additive effects; carbon sequestration; decomp...  \n",
       "1  carbon sinks; fire; forest management; meta-an...  \n",
       "2  Conservation agriculture; Soil quality; Meta-A...  \n",
       "3  Soil health\\nSoil quality\\nCover crop\\nConserv...  \n",
       "4  Three-North Shelter Forest; Soil organic carbo...  \n",
       "5  carbon sequestration; emission factor; climate...  \n",
       "6                                                     \n",
       "7  Agroforestry\\nCarbon sequestration\\nSoil\\nBiom...  \n",
       "8  Agroforestry; Carbon sequestration; Soil organ...  \n",
       "9  Pacific Northwest; Ecosystem services; Silvicu...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading database created by D. Beillouin et al.\n",
    "xlsx_file = pd.ExcelFile(\n",
    "    \"/home/er/Documents/Cirad/SOCSciCompiler/data/trainset/trainset.xlsx\"\n",
    ")\n",
    "\n",
    "# Adding label \"excluded\" or \"included\" for each MA\n",
    "df_incl = xlsx_file.parse(\"retained_meta-analyses\")\n",
    "df_excl = xlsx_file.parse(\"non_retained_meta-analyses\")\n",
    "df_incl[\"Screening\"] = \"included\"\n",
    "df_excl[\"Screening\"] = \"excluded\"\n",
    "\n",
    "size_1 = len(df_incl)\n",
    "size_2 = len(df_excl)\n",
    "size_3 = size_1 + size_2\n",
    "print(f\"Raw database contains {size_3} entries ({size_1} included MA and {size_2} excluded MA)\")\n",
    "\n",
    "# Keeping only useful attributes\n",
    "attributes_to_keep_incl = [\n",
    "    \"Screening\",\n",
    "    \"link\",\n",
    "    \"Article Title\",\n",
    "    \"Abstract\",\n",
    "    \"Keywords\",\n",
    "]\n",
    "attributes_to_keep_excl = [\n",
    "    \"Screening\",\n",
    "    \"lien pour accès\",\n",
    "    \"title\",\n",
    "    \"Abstract\",\n",
    "    \"Keywords\",\n",
    "]\n",
    "df_incl = df_incl[attributes_to_keep_incl]\n",
    "df_excl = df_excl[attributes_to_keep_excl]\n",
    "\n",
    "# Standardising columns names\n",
    "new_column_names_incl = {\"Article Title\": \"Title\", \"link\": \"DOI\"}\n",
    "new_column_names_excl = {\"title\": \"Title\", \"lien pour accès\": \"DOI\"} \n",
    "df_incl = df_incl.rename(columns=new_column_names_incl)\n",
    "df_excl = df_excl.rename(columns=new_column_names_excl)\n",
    "\n",
    "# Merging exluded and included MA into single dataframe\n",
    "raw_data = pd.concat([df_incl, df_excl], ignore_index=True)\n",
    "raw_data = raw_data.fillna(\"\")\n",
    "\n",
    "print(\"Raw database stored into 'raw_data' variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get DOIs from URLs\n",
    "def extract_doi(url):\n",
    "    if str(url).startswith(\"https://doi.org/\"):\n",
    "        return str(url)[len(\"https://doi.org/\") :]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Extracting DOIs from URLs\n",
    "df_incl[\"link\"] = df_incl[\"link\"].apply(extract_doi)\n",
    "df_excl[\"lien pour accès\"] = df_excl[\"lien pour accès\"].apply(extract_doi)\n",
    "\n",
    "# Removing exact duplicates (all columns identical) and duplicates with same DOI\n",
    "df_incl = df_incl.drop_duplicates()\n",
    "df_incl = df_incl[df_incl[\"link\"].duplicated(keep=False) == False]\n",
    "df_excl = df_excl.drop_duplicates()\n",
    "df_excl = df_excl[df_excl[\"lien pour accès\"].duplicated(keep=False) == False]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_incl = df_incl.rename(columns=new_column_names_incl)\n",
    "df_excl = df_excl.rename(columns=new_column_names_excl)\n",
    "\n",
    "\n",
    "\n",
    "# ------ PRE-PROCESSING ------\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\")) # Loading stopwords\n",
    "lemmatizer = WordNetLemmatizer() # Loading lemmatizer\n",
    "\n",
    "# TITLES\n",
    "\n",
    "for title in train_set[\"Title\"]\n",
    "\n",
    "\n",
    "\n",
    "cleaned_titles = []\n",
    "cleaned_abstracts = []\n",
    "cleaned_keywords = []\n",
    "tmp_keywords = []\n",
    "\n",
    "for title, abstract, keywords in zip(\n",
    "    train_set[\"Title\"], train_set[\"Abstract\"], train_set[\"Keywords\"]\n",
    "):\n",
    "    title = re.sub(r\"[^\\w\\s]\", \"\", title)  # Remove special characters/punctuation\n",
    "    title = title.lower()  # Convert to lowercase\n",
    "    title = title.strip()  # Remove leading/trailing spaces\n",
    "    cleaned_titles.append(title)\n",
    "\n",
    "    abstract = re.sub(r\"[^\\w\\s]\", \"\", abstract)\n",
    "    abstract = abstract.lower()\n",
    "    abstract = abstract.strip()\n",
    "    cleaned_abstracts.append(abstract)\n",
    "\n",
    "    keywords = re.split(r\"[,;\\n]\", keywords)  # Split keywords using separators (, ; \\n)\n",
    "    tmp_keywords.append(\n",
    "        [keyword.strip() for keyword in keywords if keyword.strip() != \"\"]\n",
    "    )\n",
    "    for list_kw in tmp_keywords:\n",
    "        tmp = []\n",
    "        for keyword in list_kw:\n",
    "            keyword = re.sub(r\"[^\\w\\s]\", \"\", keyword)\n",
    "            keyword = keyword.lower()\n",
    "            keyword = keyword.strip()\n",
    "            tmp.append(keyword)\n",
    "        cleaned_keywords.append(tmp)\n",
    "\n",
    "# Tokenization, Stopword Removal, Lemmatization\n",
    "tokenized_titles = []\n",
    "tokenized_abstracts = []\n",
    "tokenized_keywords = []\n",
    "\n",
    "for title in cleaned_titles:\n",
    "    tokens = nltk.word_tokenize(title)  # Tokenization\n",
    "    filtered_tokens = [\n",
    "        token for token in tokens if token not in stopwords\n",
    "    ]  # Stopword Removal\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in filtered_tokens]  # Lemmatization\n",
    "    tokenized_titles.append(lemmas)\n",
    "\n",
    "for abstract in cleaned_abstracts:\n",
    "    tokens = nltk.word_tokenize(abstract)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    tokenized_abstracts.append(lemmas)\n",
    "\n",
    "for keywords in cleaned_keywords:\n",
    "    tokenized_keyword_list = []\n",
    "    for keyword in keywords:\n",
    "        tokens = nltk.word_tokenize(keyword)\n",
    "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "        lemmas = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "        tokenized_keyword_list.extend(lemmas)\n",
    "    tokenized_keywords.append(tokenized_keyword_list)\n",
    "\n",
    "# Update the DataFrame with pre-processed data\n",
    "train_set[\"Tokenized Titles\"] = tokenized_titles\n",
    "train_set[\"Tokenized Abstracts\"] = tokenized_abstracts\n",
    "train_set[\"Tokenized Keywords\"] = tokenized_keywords\n",
    "\n",
    "rows_to_keep = [\n",
    "    \"Screening\",\n",
    "    \"Tokenized Titles\",\n",
    "    \"Tokenized Abstracts\",\n",
    "    \"Tokenized Keywords\",\n",
    "]\n",
    "\n",
    "train_set = train_set[rows_to_keep]\n",
    "train_set.columns = [\"Screening\", \"Title\", \"Abstract\", \"Keyword\"]\n",
    "\n",
    "train_set = train_set.sample(frac=1)\n",
    "train_set = train_set.drop(train_set[train_set[\"Abstract\"].apply(len) == 0].index)\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "\n",
    "empty_list_count = 0\n",
    "\n",
    "# Iterate over rows in the 'Abstract' column\n",
    "for abstract_list in train_set[\"Keyword\"]:\n",
    "    if abstract_list == []:\n",
    "        empty_list_count += 1\n",
    "\n",
    "print(\"Number of empty lists in 'Abstract' column:\", empty_list_count)\n",
    "\n",
    "\n",
    "train_set.info()\n",
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [\"a\", \"b\", \"c\"]\n",
    "c = a\n",
    "print(c)\n",
    "c = b\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
