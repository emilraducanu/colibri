{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to /home/er/nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n",
                        "[nltk_data] Downloading package wordnet to /home/er/nltk_data...\n",
                        "[nltk_data]   Package wordnet is already up-to-date!\n",
                        "[nltk_data] Downloading package omw-1.4 to /home/er/nltk_data...\n",
                        "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "import numpy as np\n",
                "import nltk\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "import pandas as pd\n",
                "\n",
                "nltk.download(\"stopwords\")\n",
                "nltk.download(\"wordnet\")\n",
                "nltk.download(\"omw-1.4\")\n",
                "\n",
                "stopwords = set(stopwords.words(\"english\"))\n",
                "lemmatizer = WordNetLemmatizer()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Raw database contains 1007 entries (217 included MA and 790 excluded MA), stored into 'raw_data' variable.\n"
                    ]
                }
            ],
            "source": [
                "# ------- LOADING DATA INTO A DATAFRAME -------\n",
                "\n",
                "\n",
                "# Loading database created by D. Beillouin et al.\n",
                "xlsx_file = pd.ExcelFile(\n",
                "    \"/home/er/Documents/Cirad/SOCSciCompiler/data/classification_trainset/classification_trainset.xlsx\"\n",
                ")\n",
                "\n",
                "# Adding label \"excluded\" or \"included\" for each MA\n",
                "df_incl = xlsx_file.parse(\"retained_meta-analyses\")\n",
                "df_excl = xlsx_file.parse(\"non_retained_meta-analyses\")\n",
                "df_incl[\"Screening\"] = \"included\"\n",
                "df_excl[\"Screening\"] = \"excluded\"\n",
                "\n",
                "# Keeping only useful attributes\n",
                "attributes_to_keep_incl = [\n",
                "    \"Screening\",\n",
                "    \"link\",\n",
                "    \"Article Title\",\n",
                "    \"Abstract\",\n",
                "    \"Keywords\",\n",
                "]\n",
                "attributes_to_keep_excl = [\n",
                "    \"Screening\",\n",
                "    \"lien pour accès\",\n",
                "    \"title\",\n",
                "    \"Abstract\",\n",
                "    \"Keywords\",\n",
                "]\n",
                "df_incl = df_incl[attributes_to_keep_incl]\n",
                "df_excl = df_excl[attributes_to_keep_excl]\n",
                "\n",
                "# Standardising columns names\n",
                "new_column_names_incl = {\"Article Title\": \"Title\", \"link\": \"DOI\"}\n",
                "new_column_names_excl = {\"title\": \"Title\", \"lien pour accès\": \"DOI\"}\n",
                "df_incl = df_incl.rename(columns=new_column_names_incl)\n",
                "df_excl = df_excl.rename(columns=new_column_names_excl)\n",
                "\n",
                "# Merging exluded and included MA into single dataframe\n",
                "raw_data = pd.concat([df_incl, df_excl], ignore_index=True)\n",
                "raw_data = raw_data.fillna(\"\")\n",
                "\n",
                "size_1 = len(df_incl)\n",
                "size_2 = len(df_excl)\n",
                "size_3 = size_1 + size_2\n",
                "print(\n",
                "    f\"Raw database contains {size_3} entries ({size_1} included MA and {size_2} excluded MA), stored into 'raw_data' variable.\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "151 rows removed because of empty DOIs. Cannot check the uniqueness.\n",
                        "0 rows removed because of empty titles. Cannot be processed by the ML model.\n",
                        "54 rows removed because of empty abstracts. Cannot be processed by the ML model.\n",
                        "8 DOI duplicates and title duplicates removed.\n",
                        "Cleaned database contains 794 entries (212 included MA and 582 excluded MA), stored into 'train_set' variable.\n"
                    ]
                }
            ],
            "source": [
                "# ------- CLEANING -------\n",
                "\n",
                "\n",
                "# Function to get DOIs from URLs\n",
                "def extract_doi(url):\n",
                "    if str(url).startswith(\"https://doi.org/\"):\n",
                "        return str(url)[len(\"https://doi.org/\") :]\n",
                "    else:\n",
                "        return None\n",
                "\n",
                "\n",
                "# Extracting DOIs from URLs\n",
                "raw_data[\"DOI\"] = raw_data[\"DOI\"].apply(extract_doi)\n",
                "\n",
                "# Removing empty DOIs rows\n",
                "raw_data = raw_data.dropna(subset=[\"DOI\"])\n",
                "size_4 = len(raw_data)\n",
                "size_5 = size_3 - size_4\n",
                "print(f\"{size_5} rows removed because of empty DOIs. Cannot check the uniqueness.\")\n",
                "\n",
                "# Removing empty titles rows\n",
                "raw_data[\"Title\"] = raw_data[\"Title\"].replace(\"\", np.nan)\n",
                "raw_data = raw_data.dropna(subset=[\"Title\"])\n",
                "size_6 = len(raw_data)\n",
                "size_7 = size_4 - size_6\n",
                "print(\n",
                "    f\"{size_7} rows removed because of empty titles. Cannot be processed by the ML model.\"\n",
                ")\n",
                "\n",
                "# Removing empty abstracts rows\n",
                "raw_data[\"Abstract\"] = raw_data[\"Abstract\"].replace(\"\", np.nan)\n",
                "raw_data = raw_data.dropna(subset=[\"Abstract\"])\n",
                "size_8 = len(raw_data)\n",
                "size_9 = size_6 - size_8\n",
                "print(\n",
                "    f\"{size_9} rows removed because of empty abstracts. Cannot be processed by the ML model.\"\n",
                ")\n",
                "\n",
                "# Removing DOIs duplicates and titles duplicates\n",
                "raw_data = raw_data.drop_duplicates(subset=[\"DOI\"], keep=\"first\")\n",
                "raw_data = raw_data.drop_duplicates(subset=\"Title\", keep=\"first\")\n",
                "size_10 = len(raw_data)\n",
                "size_11 = size_8 - size_10\n",
                "print(f\"{size_11} DOI duplicates and title duplicates removed.\")\n",
                "\n",
                "# Droping column 'DOI' now we have unique values. No needed for the ML model\n",
                "train_set = raw_data.drop(columns=[\"DOI\"])\n",
                "\n",
                "size_12 = train_set[\"Screening\"].value_counts()\n",
                "size_incl = size_12.loc[\"included\"]\n",
                "size_excl = size_12.loc[\"excluded\"]\n",
                "print(\n",
                "    f\"Cleaned database contains {size_10} entries ({size_incl} included MA and {size_excl} excluded MA), stored into 'train_set' variable.\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training set stored into 'train_set' variable and ready to be used.\n",
                        "Summary with the 20 first lines:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Screening</th>\n",
                            "      <th>Title</th>\n",
                            "      <th>Abstract</th>\n",
                            "      <th>Keywords</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>included</td>\n",
                            "      <td>[metaanalysis, effect, grassland, degradation,...</td>\n",
                            "      <td>[alpine, meadow, qinghaitibetan, plateau, qtp,...</td>\n",
                            "      <td>[alpine, meadow, degradation, community, struc...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[indirect, treatment, comparison, inotuzumab, ...</td>\n",
                            "      <td>[introductionno, headtohead, study, compared, ...</td>\n",
                            "      <td>[blinatumomab, indirect, treatment, comparison...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[temperature, sensitivity, soil, carbon, nitro...</td>\n",
                            "      <td>[climate, warming, nitrogen, n, deposition, la...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[early, angiography, patient, chronic, kidney,...</td>\n",
                            "      <td>[background, objective, general, population, e...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[nitrogen, addition, forest, soil, inhibit, de...</td>\n",
                            "      <td>[enrichment, forest, soil, inorganic, nitrogen...</td>\n",
                            "      <td>[lignin, decomposition, soil, carbon, cycling,...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[effect, different, agricultural, practice, ca...</td>\n",
                            "      <td>[agricultural, practice, particularly, land, u...</td>\n",
                            "      <td>[global, warming, potential, greenhouse, gas, ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>included</td>\n",
                            "      <td>[global, metaanalysis, soil, respiration, comp...</td>\n",
                            "      <td>[increasing, phosphorus, p, deposition, induce...</td>\n",
                            "      <td>[soil, respiration, soil, organic, matter, dec...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>included</td>\n",
                            "      <td>[response, mineral, soil, carbon, storage, har...</td>\n",
                            "      <td>[harvest, residue, retention, removal, influen...</td>\n",
                            "      <td>[harvesting, residue, plantation, priming, eff...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[effect, transdermal, testosterone, bone, musc...</td>\n",
                            "      <td>[objective, investigate, effect, testosterone,...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>included</td>\n",
                            "      <td>[effect, grazing, exclusion, carbon, sequestra...</td>\n",
                            "      <td>[widespread, land, degradation, strengthened, ...</td>\n",
                            "      <td>[grassland]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>included</td>\n",
                            "      <td>[longterm, 20, year, application, fertilizer, ...</td>\n",
                            "      <td>[increasing, soil, carbon, c, storage, crucial...</td>\n",
                            "      <td>[ipcc, guideline, longterm, fertilization, met...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[effect, agricultural, management, soil, organ...</td>\n",
                            "      <td>[background, soil, contain, largest, stock, or...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>12</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[comparison, oral, anticoagulant, among, older...</td>\n",
                            "      <td>[objective, older, adult, patient, underrepres...</td>\n",
                            "      <td>[oral, anticoagulant, atrial, fibrillation, st...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[executive, function, treatmentresistant, depr...</td>\n",
                            "      <td>[objective, aim, study, examine, executive, fu...</td>\n",
                            "      <td>[executive, function, major, depression, ect, ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[global, driver, pattern, microbial, abundance...</td>\n",
                            "      <td>[aim, soil, microorganism, play, key, role, ea...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[gender, determinant, vaccination, status, chi...</td>\n",
                            "      <td>[using, metaethnographic, method, conducted, s...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>16</th>\n",
                            "      <td>included</td>\n",
                            "      <td>[agroforestry, option, give, greatest, soil, g...</td>\n",
                            "      <td>[climate, change, mitigation, food, security, ...</td>\n",
                            "      <td>[climate, change, metaanalysis, mitigation, tr...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>17</th>\n",
                            "      <td>included</td>\n",
                            "      <td>[response, ecosystem, carbon, cycle, experimen...</td>\n",
                            "      <td>[global, warming, potentially, alters, terrest...</td>\n",
                            "      <td>[cclimate, feedback, c, efflux, c, influx, c, ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>18</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[forest, carbon, sequestration, change, respon...</td>\n",
                            "      <td>[forest, succession, contributes, global, terr...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19</th>\n",
                            "      <td>excluded</td>\n",
                            "      <td>[antipsychotic, treatment, delirium, older, ho...</td>\n",
                            "      <td>[objective, examine, evidence, efficacy, antip...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   Screening                                              Title  \\\n",
                            "0   included  [metaanalysis, effect, grassland, degradation,...   \n",
                            "1   excluded  [indirect, treatment, comparison, inotuzumab, ...   \n",
                            "2   excluded  [temperature, sensitivity, soil, carbon, nitro...   \n",
                            "3   excluded  [early, angiography, patient, chronic, kidney,...   \n",
                            "4   excluded  [nitrogen, addition, forest, soil, inhibit, de...   \n",
                            "5   excluded  [effect, different, agricultural, practice, ca...   \n",
                            "6   included  [global, metaanalysis, soil, respiration, comp...   \n",
                            "7   included  [response, mineral, soil, carbon, storage, har...   \n",
                            "8   excluded  [effect, transdermal, testosterone, bone, musc...   \n",
                            "9   included  [effect, grazing, exclusion, carbon, sequestra...   \n",
                            "10  included  [longterm, 20, year, application, fertilizer, ...   \n",
                            "11  excluded  [effect, agricultural, management, soil, organ...   \n",
                            "12  excluded  [comparison, oral, anticoagulant, among, older...   \n",
                            "13  excluded  [executive, function, treatmentresistant, depr...   \n",
                            "14  excluded  [global, driver, pattern, microbial, abundance...   \n",
                            "15  excluded  [gender, determinant, vaccination, status, chi...   \n",
                            "16  included  [agroforestry, option, give, greatest, soil, g...   \n",
                            "17  included  [response, ecosystem, carbon, cycle, experimen...   \n",
                            "18  excluded  [forest, carbon, sequestration, change, respon...   \n",
                            "19  excluded  [antipsychotic, treatment, delirium, older, ho...   \n",
                            "\n",
                            "                                             Abstract  \\\n",
                            "0   [alpine, meadow, qinghaitibetan, plateau, qtp,...   \n",
                            "1   [introductionno, headtohead, study, compared, ...   \n",
                            "2   [climate, warming, nitrogen, n, deposition, la...   \n",
                            "3   [background, objective, general, population, e...   \n",
                            "4   [enrichment, forest, soil, inorganic, nitrogen...   \n",
                            "5   [agricultural, practice, particularly, land, u...   \n",
                            "6   [increasing, phosphorus, p, deposition, induce...   \n",
                            "7   [harvest, residue, retention, removal, influen...   \n",
                            "8   [objective, investigate, effect, testosterone,...   \n",
                            "9   [widespread, land, degradation, strengthened, ...   \n",
                            "10  [increasing, soil, carbon, c, storage, crucial...   \n",
                            "11  [background, soil, contain, largest, stock, or...   \n",
                            "12  [objective, older, adult, patient, underrepres...   \n",
                            "13  [objective, aim, study, examine, executive, fu...   \n",
                            "14  [aim, soil, microorganism, play, key, role, ea...   \n",
                            "15  [using, metaethnographic, method, conducted, s...   \n",
                            "16  [climate, change, mitigation, food, security, ...   \n",
                            "17  [global, warming, potentially, alters, terrest...   \n",
                            "18  [forest, succession, contributes, global, terr...   \n",
                            "19  [objective, examine, evidence, efficacy, antip...   \n",
                            "\n",
                            "                                             Keywords  \n",
                            "0   [alpine, meadow, degradation, community, struc...  \n",
                            "1   [blinatumomab, indirect, treatment, comparison...  \n",
                            "2                                                  []  \n",
                            "3                                                  []  \n",
                            "4   [lignin, decomposition, soil, carbon, cycling,...  \n",
                            "5   [global, warming, potential, greenhouse, gas, ...  \n",
                            "6   [soil, respiration, soil, organic, matter, dec...  \n",
                            "7   [harvesting, residue, plantation, priming, eff...  \n",
                            "8                                                  []  \n",
                            "9                                         [grassland]  \n",
                            "10  [ipcc, guideline, longterm, fertilization, met...  \n",
                            "11                                                 []  \n",
                            "12  [oral, anticoagulant, atrial, fibrillation, st...  \n",
                            "13  [executive, function, major, depression, ect, ...  \n",
                            "14                                                 []  \n",
                            "15                                                 []  \n",
                            "16  [climate, change, metaanalysis, mitigation, tr...  \n",
                            "17  [cclimate, feedback, c, efflux, c, influx, c, ...  \n",
                            "18                                                 []  \n",
                            "19                                                 []  "
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# ------- PRE-PROCESSING -------\n",
                "\n",
                "\n",
                "# Function to pre-process values of columns Title, Abstract and Keywords\n",
                "def preprocessor(column: str):\n",
                "    token_col = []\n",
                "    for val in train_set[column]:\n",
                "        val = re.sub(r\"[^\\w\\s]\", \"\", val)  # Remove special characters/punctuation\n",
                "        val = val.lower()  # Convert to lowercase\n",
                "        val = val.strip()  # Remove leading/trailing spaces\n",
                "        tokens = nltk.word_tokenize(val)  # Tokenization\n",
                "        filtered_tokens = [\n",
                "            token for token in tokens if token not in stopwords\n",
                "        ]  # Stopword Removal\n",
                "        lemmas = [\n",
                "            lemmatizer.lemmatize(token) for token in filtered_tokens\n",
                "        ]  # Lemmatization\n",
                "        token_col.append(lemmas)\n",
                "    train_set[column] = token_col\n",
                "\n",
                "\n",
                "# Applying 'preprocessor()' to each column\n",
                "preprocessor(\"Title\")\n",
                "preprocessor(\"Abstract\")\n",
                "preprocessor(\"Keywords\")\n",
                "\n",
                "# Shuffling and re-indexing\n",
                "train_set = train_set.sample(frac=1)\n",
                "train_set = train_set.reset_index(drop=True)\n",
                "\n",
                "train_set.to_pickle('/home/er/Documents/Cirad/SOCSciCompiler/data/classification_trainset/classification_trainset.pkl')\n",
                "\n",
                "print(\"Training set stored into 'train_set' variable and ready to be used.\")\n",
                "print(\"Summary with the 20 first lines:\")\n",
                "train_set.head(20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ------- Handling Rare Words or Outliers & Vectorization -------\n",
                "\n",
                "\n",
                "# import pandas as pd\n",
                "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "# # Assuming your DataFrame is called 'df' and it contains the columns 'Title', 'Abstract', 'Keywords'\n",
                "\n",
                "# # Step 7: Handling Rare Words or Outliers\n",
                "# # Remove extremely rare words or outliers using a threshold\n",
                "# threshold = 0.01  # Adjust the threshold as per your requirement\n",
                "# df[\"Title\"] = df[\"Title\"].apply(\n",
                "#     lambda x: \" \".join(\n",
                "#         [\n",
                "#             word\n",
                "#             for word in x.split()\n",
                "#             if df[\"Title\"].str.count(word).sum() / len(df) > threshold\n",
                "#         ]\n",
                "#     )\n",
                "# )\n",
                "# df[\"Abstract\"] = df[\"Abstract\"].apply(\n",
                "#     lambda x: \" \".join(\n",
                "#         [\n",
                "#             word\n",
                "#             for word in x.split()\n",
                "#             if df[\"Abstract\"].str.count(word).sum() / len(df) > threshold\n",
                "#         ]\n",
                "#     )\n",
                "# )\n",
                "# df[\"Keywords\"] = df[\"Keywords\"].apply(\n",
                "#     lambda x: \" \".join(\n",
                "#         [\n",
                "#             word\n",
                "#             for word in x.split()\n",
                "#             if df[\"Keywords\"].str.count(word).sum() / len(df) > threshold\n",
                "#         ]\n",
                "#     )\n",
                "# )\n",
                "\n",
                "# # Step 8: Vectorization\n",
                "# # Perform TF-IDF vectorization on 'Title', 'Abstract', and 'Keywords'\n",
                "# vectorizer = TfidfVectorizer()\n",
                "# title_vectorized = vectorizer.fit_transform(df[\"Title\"])\n",
                "# abstract_vectorized = vectorizer.fit_transform(df[\"Abstract\"])\n",
                "# keywords_vectorized = vectorizer.fit_transform(df[\"Keywords\"])\n",
                "\n",
                "# # Convert the vectorized data into DataFrames\n",
                "# title_vectorized_df = pd.DataFrame(\n",
                "#     title_vectorized.toarray(), columns=vectorizer.get_feature_names()\n",
                "# )\n",
                "# abstract_vectorized_df = pd.DataFrame(\n",
                "#     abstract_vectorized.toarray(), columns=vectorizer.get_feature_names()\n",
                "# )\n",
                "# keywords_vectorized_df = pd.DataFrame(\n",
                "#     keywords_vectorized.toarray(), columns=vectorizer.get_feature_names()\n",
                "# )\n",
                "\n",
                "# # Concatenate the vectorized DataFrames with the original DataFrame\n",
                "# df = pd.concat(\n",
                "#     [df, title_vectorized_df, abstract_vectorized_df, keywords_vectorized_df], axis=1\n",
                "# )\n",
                "\n",
                "# # Display the updated DataFrame\n",
                "# print(df)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ds",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
